---
output: pdf_document
---


\definecolor{mypink2}{RGB}{219, 48, 122}
\definecolor{teal}{RGB}{0,128,128}
\definecolor{darkolive}{RGB}{85,107,47}
\definecolor{crimsonred}{RGB}{220,20,60}
\definecolor{midnightblue}{RGB}{25,25,112}

#\textcolor{midnightblue}{--------- DATA 643, Final Project by Burton Machado. ----------}

#***\textcolor{crimsonred}{**** Recommender System with Time and Social context. ****}***

##\textcolor{darkolive}{Project description:}



**\textcolor{teal}{We will develop a UBCF recommender system that incorporates a Time based context in the form of days of the week. It additionally and also incorporates a Social context in  the form of a relationship network. The social context is based on the connection between the users. For the purpose of this project we will consider users that are directly connected (only one hop). We will use the igraph package for analyzing the social network. In this example we will rate the movies for users using existing ratings. We will first rate a movie m2 for user u1 using the ratings data for all days of the week. Next, we will rate the movie m2 for user u1 using just the ratings for Saturdays. We will also include information about the social context in the form of how many hops users are away from each other. We will be building the whole Distance matrix for the Network, but for the sake of simplicity, we will take into account users within one hop. Here we show that users who watch movies on weekends (specifically a Saturday) are more thorough and selective in their research and hence end up liking the movies that they watch. So we end up having a watch (>3) ratings with just Saturdays data than with data for the whole week. Users who watch movies throughout the week tend to just watch movies casually and their ratings are random. We will also see  that user u1 is more close to users u21 and u27, but this fact is obscured by the ratings data for other days of the week. When we use the ratings Data, for just Saturdays, and the Social context in the form of number of hops, we bring this fact out. This will be seen in the similarity matrices that will be created, one with the ratings for the whole week and one for just the ratings for Saturdays. The code is modular and it is easy to use other days of the week and also other users and movies. Altogether we have 27 users and 25 movies. The data has been artificially created. It is contained in three files, one with the ratings permovie for each user, the other with the Day of the week that a particular movie was rated by a particular user, and one with the relationship graph between the users. We could use the ideas, most of the code, in this project to build a full-fledged Recommender system. In this project, we will produce all the data for similarity and social context, but use it manually to do our prediction. The data files are available on github.}**


```{r warning=FALSE, echo=FALSE, error=FALSE}
library(knitr)
suppressMessages(library(igraph, warn.conflicts = FALSE, quietly=TRUE))
library(pander)
#library(recommenderlab)
```

##\textcolor{darkolive}{Function definitions:}

```{r warning=FALSE}

# The following function returns the ratings for a specific day of the week denoted by the 'day' argument.
# You have to pass in the Ratings data frame (df_input) and the Context data frame (df_context).
getRatingsByDay <- function(day, df_input, df_context){
  df_temp <- df_input[,2:ncol(df_input)]
  df_temp[df_context[,2:ncol(df_context)] != day] <- NA
  df_temp <- cbind(u=df_input[,1],df_temp)
  return(df_temp)
}

# The following function creates the similarity matrix from the Ratings data frame (df_r) and Mean-centered data frame (df_mc).
get_similarity_matrix <- function(df_r, df_mc){
  #Construct the similarity matrix
  similarity_Matrix <- data.frame(names=df_r[1:nrow(df_r)-1,1])
  for(i in 1:nrow(df_mc)){
    temp <- c()
    for(j in 1:nrow(df_mc)){
      product <- sum(df_mc[i,1:(ncol(df_mc)-2)]*df_mc[j,1:(ncol(df_mc)-2)],na.rm = TRUE)/
        (df_mc$distance[i]*df_mc$distance[j])
      temp <- append(temp, product)
    }
    similarity_Matrix <- cbind(similarity_Matrix, temp)
  }
  names(similarity_Matrix)<-c('names', as.character(similarity_Matrix[,1]))
  return(similarity_Matrix)
}

# Helper function to bind the User means.
bind_user_means <- function(df_r){
  userMeans <- c()
  for(i in 1:nrow(df_r)){
    rowWithoutNA <- df_r[i, 2:ncol(df_r)][!is.na(df_r[i, 2:ncol(df_r)])]
    userMeans <- append(userMeans, round(mean(rowWithoutNA), 2))
  }
  df_r <- cbind(df_r, userMeans)
  return(df_r)
}

# Helper function to bind the Movie means.
bind_movie_means <- function(df_r){
  movieMeans <- c(NA)
  for(i in 2:ncol(df_r)){
    colWithoutNA <- df_r[,i][!is.na(df_r[,i])]
    movieMeans <- append(movieMeans, round(mean(colWithoutNA), 2))
  }
  df_r <- rbind(df_r, movieMeans)
  df_r[nrow(df_r),1] <- 'movieMeans'
  return(df_r)
}

# Function to generate Mean-centered data frame from a Ratings data frame (df_r).
get_mean_centered <- function(df_r){
  df_Mean_Centered <- df_r[,2:ncol(df_ratings)]-df_r$userMeans
  df_Mean_Centered <- df_Mean_Centered[,1:ncol(df_Mean_Centered)-1]
  df_Mean_Centered <- df_Mean_Centered[1:nrow(df_Mean_Centered)-1,]
  return(df_Mean_Centered)
}

# Function to canculate the distance and bind it to the data frame.
get_distance <- function(df_r, df_mc){
  distance <- c()
  for( i in 1:nrow(df_mc)){
    distance <- append(distance, sum(df_mc[i,]**2, na.rm = TRUE)**.5)
  }
  #Create mean centered data frame with the distance
  df_Mean_Centered_and_Distance <- cbind(df_mc, distance)
  df_Mean_Centered_and_Distance <- cbind(df_Mean_Centered_and_Distance, userMeans=df_r$userMeans[1:length(df_r$userMeans)-1])
  return(df_Mean_Centered_and_Distance)
}
```

**_____________________________________________________________**

##\textcolor{darkolive}{Data Load:}

**\textcolor{crimsonred}{Our data set consists of 3 files, one for User Ratings, one for User Time Context (on which day they watched a movie) and one for User Social Context (Who is connected to whom). We have 27 Users and 25 Movies in our data set. The data set has been artificially created, with random values.}**

**\textcolor{crimsonred}{We will first load the Ratings data from the Ratings file.}**

```{r}
# Please set the working directory to the location of the project files.
setwd('/Users/burton/001-Semester_05_CUNY/643_Recommender_Systems/Week_05')
# Create a data frame from the csv file.
#Get the ratings for all days of the Week
df_ratings <- read.csv('my_movies_ratings.csv', header = TRUE, stringsAsFactors = FALSE)
movie_matrix <- as.matrix(df_ratings[,2:ncol(df_ratings)])
```

**\textcolor{crimsonred}{Below is the heatmap of the movie ratings.}**

```{r echo=FALSE}
image(movie_matrix, main = "Heatmap of Raw Ratings")  
```

**\textcolor{crimsonred}{Below are the first 10 records of the Ratings data frame.}**

```{r echo=FALSE}
pander(head(df_ratings, 10))
```

**\textcolor{crimsonred}{We next read in the Context information. This contains the days of the week on which movies were watched.}**

```{r  echo=FALSE}
df_context <- read.csv('my_movies_time_context.csv', header = TRUE, stringsAsFactors = FALSE,na.strings = c(""))
```

**\textcolor{crimsonred}{Below are the first 10 records of the Ratings Context data frame.}**

```{r echo=FALSE}
pander(head(df_context, 10))
```

##\textcolor{darkolive}{Contextual Pre-filtering (Time-based Context):}

**\textcolor{crimsonred}{Create a data frame with just the Ratings for Saturday. This is also called a contextual pre-filtering Query, and the method is called contextual pre-filtering. This is done by joining the Ratings Matrix with the Context Matrix.}**

```{r}
#Get the ratings just for Saturday.
df_ratings_sat <- getRatingsByDay('Sat', df_ratings, df_context)
```

```{r}
movie_matrix_sat <- as.matrix(df_ratings_sat[,2:ncol(df_ratings_sat)])
```

**\textcolor{crimsonred}{Below is the heatmap of the Movie Ratings.}**

```{r echo=FALSE}
image(movie_matrix_sat, main = "Heatmap of Raw Ratings. Sat only.")  
```

**\textcolor{crimsonred}{Observe that the Saturday-only Ratings are more sparse than Ratings for all days of the week. This is as expected.}**

**\textcolor{crimsonred}{Below are the first 10 records of the Saturday Ratings data frame.}**

```{r echo=FALSE}
pander(head(df_ratings_sat, 10))
```

##\textcolor{darkolive}{Contextual Pre-filtering (Social Network-based Context):}

**\textcolor{crimsonred}{We will now read in the relationship Network data using the igraph package.}**

```{r}
# We then read in the relationships between users. Who is connected to whom.
relations_raw = read.csv("my_movies_social_context.csv", sep=",", row.names=1, header = TRUE)
relations <- as.matrix(relations_raw) 
colnames(relations) <- paste('u',1:27, sep = "")
relationsMatrix <- relations
```

**\textcolor{crimsonred}{Below are the first 10 records of the Relations (Social Context) data frame.}**

```{r}
pander(head(relationsMatrix, 10))
```

**\textcolor{crimsonred}{Note that a 1 in a user column will link that user to another user having a 1 in the same column. That is how the user network is created. For e.g. users u2 and u4 are linked through the second column of the matrix.}**

**\textcolor{crimsonred}{Below is the heatmap of the Relations (Social Context) Matrix. It gives a brief high-level view of the links between users.}**

```{r}
image(relationsMatrix, main = "Heatmap of Relations Matrix.")  
```

```{r}
# Create a Boolean matrix
relationsMatrix[relationsMatrix>=1] <- 1
# Get the term-term adjacency matrix
relationsAdjacencyMatrix <- relationsMatrix %*% t(relationsMatrix)
# inspect terms numbered 5 to 10
relationsAdjacencyMatrix[5:10,5:10]
```

```{r}
# Construct the grpah object from the above matrix
graphObject <- graph.adjacency(relationsAdjacencyMatrix, weighted=T, mode = 'undirected')
# remove loops
graphObject <- simplify(graphObject)
# set labels and degrees of vertices
V(graphObject)$label <- V(graphObject)$name
V(graphObject)$degree <- degree(graphObject)
```

**\textcolor{crimsonred}{We will now display the user Social Network graph.}**

```{r echo=FALSE}
# set seed to make the layout reproducible
set.seed(3952)
layout1 <- layout.fruchterman.reingold(graphObject)
plot(graphObject, layout=layout1)
```

**\textcolor{crimsonred}{Following is the Betweenness matrix for the Network.}**

```{r echo=FALSE}
pander(betweenness(graphObject))
```

**\textcolor{crimsonred}{Following is the Distance matrix for the Network. Note that the distances between u1, u21 and u27 are 1. We will later use this fact in our contextual filter query.}**

```{r echo=FALSE}
pander(distances(graphObject, mode="all"))
```

**\textcolor{crimsonred}{Note that the distances (Hops) between u1, u21 and u27 are 1. We will be using this fact to give more weightage to u21 and u27 with respect to u1. One way this can be done is to increase the similarity between u1 and u21, and u1 and u27.}**

##\textcolor{darkolive}{Build the Recommedations:}

```{r}
# Here we will calculate the user means and bind them to the data frame
df_ratings <- bind_user_means(df_ratings)
df_ratings_sat <- bind_user_means(df_ratings_sat)

# Here we will calculate the movie means and bind them to the data frame
df_ratings <- bind_movie_means(df_ratings)
df_ratings_sat <- bind_movie_means(df_ratings_sat)
```

**\textcolor{crimsonred}{Following is the Ratings data set (first 10 rows) with the Movie means.}**

```{r  echo=FALSE}
# Print the dataframe along with the user-means and movie-means
pander(head(df_ratings, 10))
```

**\textcolor{crimsonred}{Following is the Saturdays Ratings data set (first 10 rows) with the Movie means.}**

```{r echo=FALSE}
pander(head(df_ratings_sat, 10))
```

```{r}
# We now calculate the mean-centered values and create another dataframe.
df_Mean_Centered <- get_mean_centered(df_ratings)
df_Mean_Centered_sat <- get_mean_centered(df_ratings_sat)

# Print the mean-centered dataframe in a table.
#kable(df_Mean_Centered)

# Calculate the distances
df_Mean_Centered_and_Distance <- get_distance(df_ratings, df_Mean_Centered)
df_Mean_Centered_and_Distance_sat <- get_distance(df_ratings_sat, df_Mean_Centered_sat)
```

**\textcolor{crimsonred}{Following is the Ratings data set (first 10 rows) that is Mean-centered and  with the Distances.}**

```{r echo=FALSE}
# Print  dataframes along with the mean centered values and distance
pander(head(df_Mean_Centered_and_Distance, 10))
```

**\textcolor{crimsonred}{Following is the Saturdays Ratings data set (first 10 rows) that is Mean-centered and  with the Distances.}**

```{r echo=FALSE}
pander(head(df_Mean_Centered_and_Distance_sat, 10))
```

```{r}
#Construct the similarity matrix
similarity_Matrix_whole <- get_similarity_matrix(df_ratings, df_Mean_Centered_and_Distance)
similarity_Matrix_sat <- get_similarity_matrix(df_ratings_sat, df_Mean_Centered_and_Distance_sat)
```

**\textcolor{crimsonred}{Following is the Similarity Matrix for the whole data set.}**

```{r echo=FALSE}
#Print the similarity matrices for Whole week and just Saturdays
pander(similarity_Matrix_whole)
```

**\textcolor{crimsonred}{Following is the Similarity Matrix for the data set filtered by Saturdays.}**

```{r echo=FALSE}
pander(similarity_Matrix_sat)
```

```{r}
df_Mean_Centered_and_Distance <- cbind(Reviewer=df_ratings[1:(nrow(df_ratings)-1),1],df_Mean_Centered_and_Distance)
similarity_u1 <- sort(similarity_Matrix_whole$u1,decreasing = TRUE)
similarity_u1_sat <- sort(similarity_Matrix_sat$u1,decreasing = TRUE)
```

**\textcolor{crimsonred}{We will rate movie m2 for user u1 using ALL ratings (ratings for all days of the week). The two most similar for user u1 are u3 (0.9532) and u5(0.8907). The weights for u3 is -1.50 and for u5 is -2.42. The mean rating of u1 for m2 is 2.}**

```{r}
rating_u1_m2 <- ((0.9532*(-1.50) + 0.8907*(-2.42))/(0.9532+0.8907)) + 3.64
```

**\textcolor{crimsonred}{We will rate movie m2 for user u1 just using the Saturday ratings. We will also use the fact the distances (Hops) between u1, u21 and u27 in the user Social Network are 1. two most similar for user u1 (for Saturday) are u21 (Similarity : 0.3535) and u27(Similarity : 0.1768). The weights for u21 is 0.67 and for u27 is -0.33. The mean rating of  for m2 is 1.5.}**

```{r}
rating_u1_m2_sat <- ((0.3535*(0.67) + 0.1768*(-0.33))/(0.3535+0.1768)) + 4.50
```

**\textcolor{crimsonred}{Following is the rating for user u1 on  movie m2 taking all days of the week into context.}**

```{r echo=FALSE}
pander(rating_u1_m2)
```

**\textcolor{crimsonred}{Following is the rating for user u1 on  movie m2 taking only Saturdays ratings data and User Network into context. For the Social Network context, we use the fact the distances (Hops) between u1, u21 and u27 in the user Network are 1.}**

```{r echo=FALSE}
pander(rating_u1_m2_sat)
```

**\textcolor{crimsonred}{We can observe that the rating for user u1 for movie m2 is `r round(rating_u1_m2, 2)` if the whole weeks ratings data is used.}**

**\textcolor{crimsonred}{We can observe that the rating for user u1 for movie m2 is `r round(rating_u1_m2_sat, 2)` if only Saturdays ratings data and User Network is used.}**

**\textcolor{crimsonred}{Also users u3 and u5 obscure the proximity of users u21 and u27 who are actually more close to user u1 in terms of weekend ratings similarity. This fact is brought about by the higher rating that u1 gets when we just use Saturdays ratings data. Users u21 and u27 in our data are actually real weekend users if we check the raw ratings data. So the ratings prediction changes from a low to high when we switch to Saturdays data and User Network.}**
